import json
import re
from pathlib import Path
from typing import List, Dict, Any


KOREA_JSON_PATH = Path("corp_merged.json")
US_JSON_PATH = Path("sp_500_list.json")


def load_json(path: Path):
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def normalize_english_name(name: str) -> str:
    """
    ì˜ë¬¸ íšŒì‚¬ëª…ì—ì„œ Co., Ltd., Inc., Corporation ê°™ì€ ê¼¬ë¦¬ ì¡°ê¸ˆ ì •ë¦¬í•˜ê¸°
    ë„ˆë¬´ aggressive í•˜ê²Œ ìë¥´ì§€ ë§ê³ , í”í•œ suffix ì •ë„ë§Œ ì œê±°
    """
    if not name:
        return ""
    n = name.strip()

    # ì‰¼í‘œ ê¸°ì¤€ìœ¼ë¡œ ë’¤ ê¼¬ë¦¬ ë‚ ë¦¬ê¸° (ì˜ˆ: "Aimed Bio Inc." â†’ "Aimed Bio Inc.")
    # ì¼ë‹¨ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , suffixë§Œ ì œê±°
    n = re.sub(
        r"\b(Co\.|Corporation|Corp\.|Inc\.|Incorporated|Ltd\.|Limited|Company)\b",
        "",
        n,
        flags=re.IGNORECASE,
    )
    # ì—¬ë¶„ì˜ ê³µë°±/ì‰¼í‘œ ì •ë¦¬
    n = re.sub(r"\s+", " ", n)
    n = n.strip(" ,")
    return n

def korean_word_boundary_match(text: str, word: str) -> bool:
    """
    í•œê¸€ ê¸°ì—…ëª…ì´ ë¶€ë¶„ ë¬¸ìì—´ë¡œ ì˜ëª» ë§¤ì¹­ë˜ëŠ” ê²ƒì„ ë°©ì§€.
    ì•ë’¤ê°€ í•œê¸€/ì˜ë¬¸/ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ë§¤ì¹­ìœ¼ë¡œ ì¸ì •.
    """
    pattern = rf"(?<![ê°€-í£A-Za-z0-9]){re.escape(word)}(?![ê°€-í£A-Za-z0-9])"
    return re.search(pattern, text) is not None


def build_company_index() -> List[Dict[str, Any]]:
    """
    í•œêµ­ + ë¯¸êµ­ ê¸°ì—… ì •ë³´ë¥¼ ì½ì–´ì„œ,
    ê° ê¸°ì—…ë³„ alias ëª©ë¡ì„ í¬í•¨í•œ í†µí•© ì¸ë±ìŠ¤ë¥¼ ë§Œë“ ë‹¤.
    """
    kor_list = load_json(KOREA_JSON_PATH)
    us_list = load_json(US_JSON_PATH)

    index: List[Dict[str, Any]] = []

    # ğŸ‡°ğŸ‡· í•œêµ­ ìƒì¥ì‚¬
    for row in kor_list:
        aliases = set()

        name = (row.get("name") or "").strip()
        eng = (row.get("corp_eng_name") or "").strip()
        ticker = (row.get("ticker") or "").strip()

        if name:
            aliases.add(name)

        if eng:
            aliases.add(eng)
            simplified_eng = normalize_english_name(eng)
            if simplified_eng and simplified_eng.lower() != eng.lower():
                aliases.add(simplified_eng)

        # í•„ìš”í•˜ë©´ ìˆ«ì í‹°ì»¤ë„ aliasë¡œ:
        numeric_ticker = "".join(ch for ch in ticker if ch.isdigit())
        if numeric_ticker:
            aliases.add(numeric_ticker)

        if not aliases:
            continue

        index.append(
            {
                "source": "KR",
                "name": name,
                "corp_eng_name": eng,
                "ticker": ticker,
                "exchange": row.get("exchange"),
                "corp_code": row.get("corp_code"),
                "raw": row,  # ì›ë³¸ ì „ì²´ ë ˆì½”ë“œ
                "aliases": sorted(aliases, key=len, reverse=True),  # ê¸¸ì´ ê¸´ ê²ƒë¶€í„°
            }
        )

    # ğŸ‡ºğŸ‡¸ ë¯¸êµ­ S&P 500
    for row in us_list:
        aliases = set()

        company = (row.get("company") or "").strip()
        company_kor = (row.get("company_kor") or "").strip()
        symbol = (row.get("symbol") or "").strip()

        if company:
            aliases.add(company)
            aliases.add(normalize_english_name(company))
        if company_kor:
            aliases.add(company_kor)
        if symbol:
            aliases.add(symbol)

        aliases = {a for a in aliases if a}  # ë¹ˆ ë¬¸ìì—´ ì œê±°

        if not aliases:
            continue

        index.append(
            {
                "source": "US",
                "company": company,
                "company_kor": company_kor,
                "symbol": symbol,
                "CIK": row.get("CIK"),
                "raw": row,
                "aliases": sorted(aliases, key=len, reverse=True),
            }
        )

    return index


def extract_companies_from_news(text: str, company_index: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ë‰´ìŠ¤ ë³¸ë¬¸(text)ì—ì„œ ì–´ë–¤ ê¸°ì—…ì´ ì–¸ê¸‰ëëŠ”ì§€ alias ê¸°ë°˜ìœ¼ë¡œ ì°¾ì•„ë‚¸ë‹¤.
    - company_index: build_company_index() ê²°ê³¼
    """
    results = []

    # ì†Œë¬¸ìí™” (í•œê¸€ì—” ì˜í–¥ ì—†ìŒ)
    text_norm = text.lower()

    for comp in company_index:
        matched_aliases = []

        for alias in comp["aliases"]:
            alias_norm = alias.lower()
            if not alias_norm:
                continue

            # ì•ŒíŒŒë²³(ì˜ë¬¸ì)ì´ í•˜ë‚˜ë¼ë„ ë“¤ì–´ê°„ alias â†’ ë‹¨ì–´ ê²½ê³„ë¡œ ë§¤ì¹­
            if re.search(r"[a-z]", alias_norm):
                # \bNVDA\b, \bNvidia\b ì´ëŸ° ì‹
                pattern = r"\b" + re.escape(alias_norm) + r"\b"
                if re.search(pattern, text_norm):
                    matched_aliases.append(alias)
            else:
                if korean_word_boundary_match(text_norm, alias_norm):
                    matched_aliases.append(alias)

        if matched_aliases:
            # ì¤‘ë³µ ì œê±°
            unique_matched = sorted(set(matched_aliases), key=len, reverse=True)
            result = {
                "source": comp["source"],
                "matched_aliases": unique_matched,
            }
            # í•œêµ­/ë¯¸êµ­ êµ¬ë¶„í•´ì„œ í•„ë“œ ë„£ê¸°
            if comp["source"] == "KR":
                result.update(
                    {
                        "name": comp.get("name"),
                        "corp_eng_name": comp.get("corp_eng_name"),
                        "ticker": comp.get("ticker"),
                        "exchange": comp.get("exchange"),
                        "corp_code": comp.get("corp_code"),
                    }
                )
            else:  # US
                result.update(
                    {
                        "company": comp.get("company"),
                        "company_kor": comp.get("company_kor"),
                        "symbol": comp.get("symbol"),
                        "CIK": comp.get("CIK"),
                    }
                )

            results.append(result)

    return results


if __name__ == "__main__":
    

    with open("news1.txt", "r", encoding="utf-8") as file:
        news_text = file.read()

    company_index = build_company_index()
    found = extract_companies_from_news(news_text, company_index)

    print("=== FOUND COMPANIES ===")
    for c in found:
        print(c)
